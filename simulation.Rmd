---
title: "Simulation"
output: github_document
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

library(tidyverse)

set.seed(1)
```

## Simulation
Simulation function

```{r}
sim_regression = function(n, beta0 = 2, beta1 = 3) {
  
  sim_data = tibble(
    x = rnorm(n, mean = 1, sd = 1),
    y = beta0 + beta1 * x + rnorm(n, 0, 1)
  )
  
  ls_fit = lm(y ~ x, data = sim_data)
  
  tibble(
    beta0_hat = coef(ls_fit)[1],
    beta1_hat = coef(ls_fit)[2]
  )
}
```

Run it a few times.

```{r}
sim_regression(n = 30, beta0 = 2, beta1 = 3)
```

Iterate simulations!!

```{r}
output = vector("list", length = 100)

for (i in 1:100) {
  output[[i]] = sim_regression(n = 30, beta0 = 2, beta1 = 3)
}

#output---100 lists
results = 
  output %>% 
  bind_rows()
```

```{r}
results %>% 
  summarize(mean_b0 = mean(beta0_hat),
            mean_b1 = mean(beta1_hat))

results %>% 
  ggplot(aes(x = beta0_hat, y = beta1_hat)) + 
  geom_point()
```

A better way to iterate ...when no input list
```{r}
?rerun
results = 
  rerun(1000, sim_regression(30, 2, 3)) %>% 
  bind_rows()
```

```{r}
results %>% 
  gather(key = parameter, value = estimate, beta0_hat:beta1_hat) %>% 
  group_by(parameter) %>% 
  summarize(emp_mean = mean(estimate),
            emp_var = var(estimate)) %>% 
  knitr::kable(digits = 3)
```

## Increase sample size

```{r}
n_list = list("n_30"  = 30, 
              "n_60"  = 60, 
              "n_120" = 120, 
              "n_240" = 240)
output = vector("list", length = 4)

for (i in 1:4) {
  output[[i]] = 
    rerun(100, sim_regression(n = n_list[[i]], 2, 3)) %>% 
    bind_rows
}
```

Recast using `map`s ...
n = sample size = number of observations
n_runs = times of runs
```{r}
simulate_n_regressions = function(n_runs = 100, n, beta0 = 2, beta1 = 3) {
  
  rerun(n_runs, sim_regression(n, beta0, beta1)) %>% 
    bind_rows()
  
}
simulate_n_regressions(100, 30, 2, 3)
simulate_n_regressions(n = 30)
simulate_n_regressions(150, 30, 20, -30)
```

```{r}
map(n_list, ~simulate_n_regressions(n_runs = 100, n = .x, beta0 = 2, beta1 = 3))
```

Use a list column

```{r}
sim_results = 
  tibble(sample_size = c(30, 60, 120, 240)) %>% 
  mutate(estimate_dfs = map(.x = sample_size, ~simulate_n_regressions(n_runs = 1000, n = .x))) %>% 
  unnest
```

sample size increase, var decreases.
```{r}
sim_results %>% 
  group_by(sample_size) %>% 
  summarize(emp_var_b1 = var(beta1_hat))
```

plots
```{r}
sim_results %>% 
  ggplot(aes(x = beta0_hat, y = beta1_hat)) + 
  geom_point() +
  facet_grid(~sample_size)
```

```{r}
sim_results %>% 
  mutate(
    sample_size = str_c("n = ", sample_size),
    sample_size = fct_inorder(sample_size)) %>% 
  ggplot(aes(x = sample_size, y = beta1_hat, fill = sample_size)) + 
  geom_violin()
```
the width of the distribution shrinks as sample size grows
```{r}
sim_results %>% 
  mutate(
    sample_size = str_c("n = ", sample_size),
    sample_size = fct_inorder(sample_size)) %>% 
  ggplot(aes(x = beta0_hat, y = beta1_hat)) + 
  geom_point(alpha = .2) + 
  facet_grid(~sample_size)
```

```{r}
sim_results %>% 
  gather(key = parameter, value = estimate, beta0_hat:beta1_hat) %>% 
  group_by(parameter, sample_size) %>% 
  summarize(emp_mean = mean(estimate),
            emp_var = var(estimate)) %>% 
  knitr::kable(digits = 3)
```

## Publication bias

New `sim_regression` function.

```{r}
sim_regression = function(n_samp = 30, beta0 = 2, beta1 = 3) {
  
  sim_data = tibble(
    x = rnorm(n_samp),
    y = beta0 + beta1 * x + rnorm(n_samp, 0, sqrt(50))
  )
  ls_fit = lm(y ~ x, data = sim_data)
  broom::tidy(ls_fit) 
}
```

Simulate for various SLOPE values. This code chunk takes a while to run, but it's good to have 10000 iterations -- later, when we average over significant results, we end up with a much smaller number of iterations when power is low.

```{r cache=TRUE}
sim_results = 
  tibble(beta1_true = 0:6) %>% 
  mutate(
    estimate_dfs = map(.x = beta1_true, ~simulate_n_regressions(n_runs = 10000, n = 30, beta1 = .x))
  )  
```

Tidy up results.

```{r}
sim_results = 
  sim_results %>% 
  unnest() %>% 
  filter(term == "x") %>% 
  select(beta1_true, estimate, p.value) %>% 
  mutate(significant = as.numeric(p.value < 0.05))
```

```{r}
sim_results %>% 
  group_by(beta1_true) %>% 
  summarize(mean_est = mean(estimate),
            power = mean(significant))
```

Look at the real thing of interest

```{r}
results_summary = 
  sim_results %>% 
  group_by(beta1_true) %>%
  nest() %>% 
  mutate(
    all = map_dbl(.x = data, ~ .x %>% pull(estimate) %>% mean),
    signif = map_dbl(.x = data, ~ .x %>% filter(significant == 1) %>% pull(estimate) %>% mean)
  ) %>% 
  select(-data) %>% 
  gather(key = results, value = average, all:signif) 
results_summary %>% 
  ggplot(aes(x = beta1_true, y = average, color = results)) + 
  geom_point() +
  geom_path() 
```


```{r}
sim_results %>% 
  ggplot(aes(x = estimate)) + geom_histogram() + 
  facet_grid(significant ~ beta1_true)
```